{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import seaborn as sn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, Y_train),(X_test,Y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 480x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = 7\n",
    "plt.matshow(X_train[c])\n",
    "Y_train[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ONED_X_train = X_train.reshape(len(X_train),28*28)\n",
    "ONED_X_test = X_test.reshape(len(X_test),28*28) #Stworzenie  tablicy o dlugosci wszystkich danych wbazie \n",
    "\n",
    "ONED_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 540us/step - loss: 9.8413 - accuracy: 0.8403\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 6.0845 - accuracy: 0.8785\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 536us/step - loss: 5.7143 - accuracy: 0.8820\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 532us/step - loss: 5.5571 - accuracy: 0.8854\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 533us/step - loss: 5.4133 - accuracy: 0.8871\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d1cf246a60>"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10,input_shape=(784,),activation = 'sigmoid') #na wyjsciu mamy warstwe 10 neuronow -cyfry, a na inpucie jest 784 pixeli\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(ONED_X_train,Y_train,epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333333, 0.68627451, 0.10196078,\n",
       "        0.65098039, 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117647,\n",
       "        0.36862745, 0.60392157, 0.66666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235294, 0.6745098 ,\n",
       "        0.99215686, 0.94901961, 0.76470588, 0.25098039, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215686, 0.93333333, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.98431373, 0.36470588, 0.32156863,\n",
       "        0.32156863, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.77647059,\n",
       "        0.71372549, 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31372549, 0.61176471,\n",
       "        0.41960784, 0.99215686, 0.99215686, 0.80392157, 0.04313725,\n",
       "        0.        , 0.16862745, 0.60392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.60392157, 0.99215686, 0.35294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509804, 0.99215686, 0.74509804, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313725, 0.74509804, 0.99215686, 0.2745098 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.1372549 , 0.94509804, 0.88235294,\n",
       "        0.62745098, 0.42352941, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764706, 0.94117647,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.17647059,\n",
       "        0.72941176, 0.99215686, 0.99215686, 0.58823529, 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.36470588, 0.98823529, 0.99215686, 0.73333333,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.97647059, 0.99215686, 0.97647059,\n",
       "        0.25098039, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980392, 0.71764706, 0.99215686, 0.99215686, 0.81176471,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.58039216, 0.89803922,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.71372549,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705882, 0.86666667, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.78823529, 0.30588235, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882353,\n",
       "        0.83529412, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.77647059, 0.31764706, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058824, 0.85882353, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.76470588, 0.31372549,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568627,\n",
       "        0.6745098 , 0.88627451, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156863, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333333,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137255, 0.52941176,\n",
       "        0.51764706, 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train = X_train / 255\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONED_X_train = X_train.reshape(len(X_train),28*28)\n",
    "ONED_X_test = X_test.reshape(len(X_test),28*28) #Stworzenie  tablicy o dlugosci wszystkich danych wbazie "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.4729 - accuracy: 0.8759\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 1s 525us/step - loss: 0.3035 - accuracy: 0.9157\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 1s 531us/step - loss: 0.2833 - accuracy: 0.9210\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 1s 527us/step - loss: 0.2730 - accuracy: 0.9236\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 1s 528us/step - loss: 0.2663 - accuracy: 0.9254\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d1cf257fd0>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(10,input_shape=(784,),activation = 'sigmoid') #Zmiana wartosci od jeden do 255 na od 0 do 1 poprzez podzielenie na 255\n",
    "    #   spowodowało zwiekszenie dokladosci SCALLING\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(ONED_X_train,Y_train,epochs = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/313 [..............................] - ETA: 18s - loss: 65.6530 - accuracy: 0.9688"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 518us/step - loss: 45.8425 - accuracy: 0.9153\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[45.842491149902344, 0.9153000116348267]"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ONED_X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 1s 646us/step - loss: 0.2794 - accuracy: 0.9205\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 1s 630us/step - loss: 0.1263 - accuracy: 0.9632\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 1s 657us/step - loss: 0.0878 - accuracy: 0.9738\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.0669 - accuracy: 0.9798\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 1s 646us/step - loss: 0.0535 - accuracy: 0.9837\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 1s 644us/step - loss: 0.0422 - accuracy: 0.9869\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 1s 643us/step - loss: 0.0344 - accuracy: 0.9895\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 1s 641us/step - loss: 0.0286 - accuracy: 0.9911\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 1s 648us/step - loss: 0.0226 - accuracy: 0.9933\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.0198 - accuracy: 0.9939\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 1s 635us/step - loss: 0.0166 - accuracy: 0.9951\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 1s 634us/step - loss: 0.0138 - accuracy: 0.9955\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 1s 634us/step - loss: 0.0118 - accuracy: 0.9962\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.0107 - accuracy: 0.9966\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 1s 632us/step - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.0090 - accuracy: 0.9972\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 1s 636us/step - loss: 0.0067 - accuracy: 0.9980\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 1s 640us/step - loss: 0.0065 - accuracy: 0.9981\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 1s 645us/step - loss: 0.0071 - accuracy: 0.9978\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 1s 654us/step - loss: 0.0066 - accuracy: 0.9979\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 1s 659us/step - loss: 0.0046 - accuracy: 0.9987\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 1s 640us/step - loss: 0.0045 - accuracy: 0.9987\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.0041 - accuracy: 0.9988\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 1s 639us/step - loss: 0.0043 - accuracy: 0.9987\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 1s 645us/step - loss: 0.0054 - accuracy: 0.9981\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 1s 639us/step - loss: 0.0043 - accuracy: 0.9984\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 1s 640us/step - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 1s 640us/step - loss: 0.0046 - accuracy: 0.9984\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.0027 - accuracy: 0.9993\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.0035 - accuracy: 0.9988\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 1s 642us/step - loss: 0.0037 - accuracy: 0.9988\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 1s 637us/step - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 1s 638us/step - loss: 0.0028 - accuracy: 0.9991\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 1s 644us/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 1s 656us/step - loss: 0.0033 - accuracy: 0.9990\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 1s 668us/step - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 1s 683us/step - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 1s 657us/step - loss: 0.0023 - accuracy: 0.9994\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 1s 645us/step - loss: 0.0040 - accuracy: 0.9986\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 1s 682us/step - loss: 0.0032 - accuracy: 0.9991\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 1s 647us/step - loss: 0.0042 - accuracy: 0.9988\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 1s 677us/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 1s 673us/step - loss: 0.0052 - accuracy: 0.9983\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 1s 661us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 1s 671us/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 1s 651us/step - loss: 0.0039 - accuracy: 0.9988\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 1s 658us/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 1s 652us/step - loss: 0.0032 - accuracy: 0.9988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d1cf3d3220>"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100,input_shape=(784,),activation='relu'),\n",
    "    keras.layers.Dense(10,activation = 'sigmoid') #Zmiana wartosci od jeden do 255 na od 0 do 1 poprzez podzielenie na 255\n",
    "    #   spowodowało zwiekszenie dokladosci SCALLING\n",
    "])\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(ONED_X_train,Y_train,epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 550us/step - loss: 41.2260 - accuracy: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[41.22602844238281, 0.977400004863739]"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(ONED_X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
